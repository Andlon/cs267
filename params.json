{"name":"CS 267 - Andreas Longva","tagline":"UC Berkeley CS 267 Spring 2015 - assignments and more","body":"# Short biography: Andreas Longva\r\n\r\nI am an international student from the Norwegian University of Science and Technology (NTNU). I came to Berkeley this fall, and I will stay here until the end of this spring semester, at which point I will go back to Norway to start work on my Master's thesis in industrial mathematics. \r\n\r\nDue to the way my study program is organized, I will not engage in research activities before thesis work, and so I do not have any formal research areas. Some of my academic interests revolve around using numerical methods, such as discretizations of PDEs or optimization, along with elements from computer science, to solve interesting real-world problems. Moreover, I am passionate about software, and I've spent a great deal of time on personal projects in a broad range of software categories, and I've had the chance to work on interesting software projects during summer internships, such as control systems for offshore supply vessels and training simulators for offshore operations.\r\n\r\nI would be especially interested in working on the parallelization of solvers for physical/mechanical systems, perhaps particularly related to fluid dynamics, linear algebra problems or graph algorithms with interesting applications, though I do not have particular examples from my own study to motivate this.\r\n\r\nSo far, my experience with parallel programming is mainly limited to the use of threads and synchronization primitives to run separate tasks on a single computer at the same time to minimize waiting time (i.e. run processes in the background to keep a graphical user interface responsive and fluid), with not so much focus on performance. With this course, I am hoping to learn about useful abstractions and techniques that would let me design algorithms for performance-dependent projects that run efficiently on parallel platforms, both for small-scale personal computers and large-scale scientific computing.\r\n\r\n# Assignment #0\r\n## **BOINC**\r\n**B**erkeley **O**pen **I**nfrastructure for **N**etwork **C**omputing, or just **BOINC**, is a grid computing platform where volunteers contribute computer power to solve (mainly scientific) large scale problems. _BOINC_ has been developed by the same team that developed _SETI@home_, a distributed project for volunteers to contribute to the search for extraterrestrial intelligence. The _SETI@home_ client was initially designed exclusively for contribution to the _SETI@home_ project. With the development of _BOINC_, which serves as an abstraction for running projects such as _SETI@home_, _SETI@home_ was moved to _BOINC_, and today a large number of distributed volunteer projects are based on the _BOINC_ platform.\r\n\r\n_BOINC_, like other grid computing platforms, distributes entirely independent tasks to different clients. Hence, _BOINC_ is only well-suited for embarrassingly parallel problems. Notably, the system involves a certain amount of redundancy in that multiple clients receive the same workload, after which the results are compared in order to combat clients that deliberately submit wrong results.\r\n\r\nSince _BOINC_ is essentially middleware, it can be used for scientific problems in virtually any field. The nature and implementation of the application running on _BOINC_ determines the full extent of the parallel platforms involved. In addition to the overall grid computing pattern, applications may use a single processor on a user's computer, multiple processors or even the GPU. Hence you could consider certain _BOINC_ applications to be hybrid applications. For instance, the _Asteroids@home_ project that runs on _BOINC_ is capable of running workload units on _NVIDIA_ GPUs. The overall application can thus be viewed as a hybrid of distributed and vector parallel computation.\r\n\r\nDepending on the nature of the individual projects running on _BOINC_, simulation results may be routinely compared with experimental results. This is the case with the _ATLAS@home_ project, which uses the BOINC infrastructure to run simulations of the ATLAS particle physics experiment at CERN. \r\n\r\nThe _BOINC_ infrastructure consists of servers and clients, and is further subdivided into different separate processes. The main development language behind most of the technology is C++, and the full stack encompasses a number of technologies, including network, database management, desktop and web interfaces.\r\n\r\nThe total floating point computing power of _BOINC_ projects is estimated at about 9.9 petaFLOPS on average (January 16, 2015). Although not directly comparable, this is of the same order of magnitude as the fastest supercomputers in the world. To illustrate: According to _Top500_, the current best-performing supercomputer on the _LINPACK_ benchmark has a performance of about 33.9 petaFLOPS.\r\n\r\nThe project lists a number of upcoming projects which aim to improve weaknesses of the current infrastructure. Most notably, the current job scheduler on the client-side uses some O(n^2) algorithms that can cause unnecessarily high CPU usage when facing high quantities of small jobs. Furthermore, the GPU support is currently limited to a certain heterogeneity of devices when dealing with systems that have multiple GPUs. This implies that _BOINC_ is not able to fully utilize the GPUs available in certain systems that have many different types of GPUs.","google":"","note":"Don't delete this file! It's used internally to help with page regeneration."}